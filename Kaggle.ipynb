{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOD2eQWgHpieHziZN0a64r9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zghabr/class/blob/main/Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkUjP6nY4z-3"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Al3BK35BQf"
      },
      "source": [
        "pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elkDrgzo9Lnz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGZLVyET9YQI"
      },
      "source": [
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0CALdm_9ptV"
      },
      "source": [
        "ls /gdrive/MyDrive/Dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEuT6HmS45gP"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa.display as display\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import random_split, DataLoader, Dataset\n",
        "import torchaudio.transforms as T\n",
        "import torchvision\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14a01eox48Yd"
      },
      "source": [
        "sample = wavfile.read('/gdrive/MyDrive/Dataset/go/b41a92a3_nohash_1.wav')\n",
        "sample_array = np.array(sample[1],dtype=float)\n",
        "display.waveplot(sample_array, sr=sample[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyTMtZCh-Z90"
      },
      "source": [
        "ipd.Audio(sample_array, rate=sample[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQP4wBmO-epc"
      },
      "source": [
        "sample_spec = librosa.feature.melspectrogram(sample_array, sr=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oHP-sFR-gDz"
      },
      "source": [
        "a = np.max\n",
        "display.specshow(librosa.core.power_to_db(sample_spec,ref= a), sr=16000,\n",
        "                 x_axis='ms', y_axis='mel')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAsFfvu0-jZU"
      },
      "source": [
        "sample_spec.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqpJAhF6-njE"
      },
      "source": [
        "data_dir = '/gdrive/MyDrive/Dataset/'\n",
        "classes = os.listdir(data_dir)\n",
        "print(classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQVI_vF1-1Zn"
      },
      "source": [
        "def convert():\n",
        "    X = []\n",
        "    for subdir, dirs, files in os.walk(data_dir + 'go'):\n",
        "        for file in files:\n",
        "            x =  wavfile.read(os.path.join(subdir, file))\n",
        "            x_array = np.array(x[1],dtype=float)\n",
        "            X.append(x_array)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcwHpYdU-66r"
      },
      "source": [
        "go = convert()\n",
        "print(go[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCN8tWvw_Rxr"
      },
      "source": [
        "print(go)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpZFHxIAF4kL"
      },
      "source": [
        "for x in go:\n",
        "    print(len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEqxkqazF_NZ"
      },
      "source": [
        "sample_spec = librosa.feature.melspectrogram(go[0], sr=16000)\n",
        "db_img = librosa.core.power_to_db(sample_spec,ref= a)\n",
        "display.specshow(db_img, sr=16000,\n",
        "                 x_axis='ms', y_axis='mel')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPGxy_h6GTtg"
      },
      "source": [
        "ipd.Audio(go[1], rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3uqnDQwGawB"
      },
      "source": [
        "melspec = T.MelSpectrogram(sample_rate=16000,\n",
        "                                        n_fft=2048,\n",
        "                                        hop_length=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9ixLGtUGfP1"
      },
      "source": [
        "yad = melspec(torch.Tensor(go[0]))\n",
        "yad = yad.unsqueeze(0)\n",
        "print(yad.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcYs9P2sGmdc"
      },
      "source": [
        "print(go[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WrUoeU3Gs4Z"
      },
      "source": [
        "go[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1qr9FZZGxTG"
      },
      "source": [
        "print(yad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOyicMCWG8oa"
      },
      "source": [
        "yad.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1NCCT9VHAGu"
      },
      "source": [
        "print(len(go))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcS__At4HCW-"
      },
      "source": [
        "for subdir, dirs, files in os.walk(data_dir + 'go'):\n",
        "    print(len(files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i58PvVH8HGlB"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "for dirname, _, filenames in os.walk('/gdrive/MyDrive/Dataset/ourdataset/train/'):\n",
        "    melspec = T.MelSpectrogram(sample_rate=16000,n_fft=2048,hop_length=512)\n",
        "    for filename in filenames:\n",
        "        if dirname.split('/')[-1]:\n",
        "            x = wavfile.read(os.path.join(dirname, filename))\n",
        "            x_array = np.array(x[1],dtype=float)\n",
        "            yad = melspec(torch.Tensor(x_array))\n",
        "            yad = yad.unsqueeze(0)\n",
        "            X.append(yad)\n",
        "            y.append(dirname.split('/')[-1])\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHfk7ecFHWzO"
      },
      "source": [
        "def Convert_To_Tensors(data_dir):\n",
        "    melspec = T.MelSpectrogram(sample_rate=16000,n_fft=2048,hop_length=512)\n",
        "    for subdir, dirs, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            x =  wavfile.read(os.path.join(subdir, file))\n",
        "            x_array = np.array(x[1],dtype=float)\n",
        "            yad = melspec(torch.Tensor(x_array))\n",
        "            yad = yad.unsqueeze(0)\n",
        "            X.append(yad)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T664uuTHdLF"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvgr7x73HePZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import pandas as pd\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "mlb.fit(pd.Series(y).fillna(\"missing\").str.split(', '))\n",
        "y_mlb = mlb.transform(pd.Series(y).fillna(\"missing\").str.split(', '))\n",
        "mlb.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6utg_WSuHgkc"
      },
      "source": [
        "y_mlb = torch.tensor(y_mlb)\n",
        "y_mlb_labels = torch.max(y_mlb, 1)[1]\n",
        "print(y_mlb_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMwqqVbWHjHa"
      },
      "source": [
        "y_mlb = torch.tensor(y_mlb_labels, dtype=torch.long)\n",
        "print(y_mlb.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIJbtPQSHl_I"
      },
      "source": [
        "print(X[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AIqKpc-HutD"
      },
      "source": [
        "X_train, X_valtest, y_train, y_valtest = train_test_split(X,y_mlb,test_size=0.2, random_state=37)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_valtest,y_valtest,test_size=0.5, random_state=37)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqPJMim4HwVP"
      },
      "source": [
        "print(len(X_train))\n",
        "X_train[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDlbPPioHzOZ"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3eiDTp8H1kh"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.targets[index]\n",
        "            \n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyE1gKm-H3YQ"
      },
      "source": [
        "train_ds = MyDataset(X_train,y_train)\n",
        "val_ds = MyDataset(X_val,y_val)\n",
        "test_ds = MyDataset(X_test,y_test)\n",
        "batch_size=128\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size,shuffle=True, pin_memory=True,num_workers=4 )\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size,pin_memory=True,num_workers=4 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2I47B2wH5PN"
      },
      "source": [
        "print(train_ds[0][0][0][0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_bIm66mH67h"
      },
      "source": [
        "def accuracy(outs, labels):\n",
        "    _, preds = torch.max(outs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoiQzPnqH9vx"
      },
      "source": [
        "class ModelBase(nn.Module):\n",
        "\n",
        "    # defines mechanism when training each batch in dl\n",
        "    def train_step(self, batch):\n",
        "        xb, labels = batch\n",
        "        outs = self(xb)\n",
        "        loss = F.cross_entropy(outs, labels)\n",
        "        return loss\n",
        "\n",
        "    # similar to `train_step`, but includes acc calculation & detach\n",
        "    def val_step(self, batch):\n",
        "        xb, labels = batch\n",
        "        outs = self(xb)\n",
        "        loss = F.cross_entropy(outs, labels )\n",
        "        acc = accuracy(outs,   labels)\n",
        "        return {'loss': loss.detach(), 'acc': acc.detach()}\n",
        "\n",
        "    # average out losses & accuracies from validation epoch\n",
        "    def val_epoch_end(self, outputs):\n",
        "        batch_loss = [x['loss'] for x in outputs]\n",
        "        batch_acc = [x['acc'] for x in outputs]\n",
        "        avg_loss = torch.stack(batch_loss).mean()\n",
        "        avg_acc = torch.stack(batch_acc).mean()\n",
        "        return {'avg_loss': avg_loss, 'avg_acc': avg_acc}\n",
        "\n",
        "    # print all data once done\n",
        "    def epoch_end(self, epoch, avgs, test=False):\n",
        "        s = 'test' if test else 'val'\n",
        "        print(f'Epoch #{epoch + 1}, {s}_loss:{avgs[\"avg_loss\"]}, {s}_acc:{avgs[\"avg_acc\"]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "938HSv5JIKds"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_dl):\n",
        "    # eval mode\n",
        "    model.eval()\n",
        "    outputs = [model.val_step(batch) for batch in val_dl]\n",
        "    return model.val_epoch_end(outputs)\n",
        "\n",
        "\n",
        "def fit(epochs, lr, model, train_dl, val_dl, opt_func=torch.optim.Adam):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    # define optimizer\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    # for each epoch...\n",
        "    for epoch in range(epochs):\n",
        "        # training mode\n",
        "        model.train()\n",
        "        # (training) for each batch in train_dl...\n",
        "        for batch in tqdm(train_dl):\n",
        "            # pass thru model\n",
        "            loss = model.train_step(batch)\n",
        "            # perform gradient descent\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # validation\n",
        "        res = evaluate(model, val_dl)\n",
        "        # print everything useful\n",
        "        model.epoch_end(epoch, res, test=False)\n",
        "        # append to history\n",
        "        history.append(res)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z70lGj07INC4"
      },
      "source": [
        "class Classifier(ModelBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(1, 512, kernel_size=3, padding=1),   # 512 x 128 x 32 \n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            \n",
        "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1), # 256 x 64 x 16\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            \n",
        "            nn.Conv2d(256,128, kernel_size=3, stride=1, padding=1), # 128 x 32x 8\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Flatten(),\n",
        "            nn.Linear(8192, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 30))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R06JK513IPIy"
      },
      "source": [
        "model = Classifier()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-d41J-xIRT7"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB4npyRRITwD"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLaM0bmmIV1E"
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTfY7_dLIXe0"
      },
      "source": [
        "model = to_device(Classifier(), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JQ3Kr79IaJe"
      },
      "source": [
        "lr = 1e-5\n",
        "epochs = 10\n",
        "print(val_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSGdxq_JIcAv"
      },
      "source": [
        "evaluate(model, val_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6OCXA35Iey0"
      },
      "source": [
        "history= []\n",
        "history += fit(epochs, lr, model, train_dl, val_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ50hbxQIgkB"
      },
      "source": [
        "plt.plot([x['avg_loss'] for x in history])\n",
        "plt.title('Losses over epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUMPtyv2IifC"
      },
      "source": [
        "plt.plot([x['avg_acc'] for x in history])\n",
        "plt.title('Accuracy over epochs')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('acc')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lUZiZL0IkE6"
      },
      "source": [
        "torch.save(model.state_dict(), 'Classifier.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9o8Qh7dInJ6"
      },
      "source": [
        "model.load_state_dict(torch.load('Classifier.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zVId4k-InC7"
      },
      "source": [
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size,pin_memory=True,num_workers=4 )\n",
        "evaluate(model, test_dl)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPZECbPaIrO7"
      },
      "source": [
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size,pin_memory=True,num_workers=4 )\n",
        "test_dl = DeviceDataLoader(test_dl, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZgDKNdsIs1U"
      },
      "source": [
        "evaluate(model, test_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isY3Lej1IvUV"
      },
      "source": [
        "!pip install jovian --upgrade -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7UgN0QwIvJl"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK_ua316I0kh"
      },
      "source": [
        "project_name = 'Audio_Classifier_1'\n",
        "jovian.commit(project=project_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}